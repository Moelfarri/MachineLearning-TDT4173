{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 14\n",
    "## Competition Name : Moscow Housing\n",
    "## Elias Elfarri    , ID: 473700\n",
    "## Nora Valen       , ID: 490606\n",
    "## Muhammad Sarmad  , ID: 190729\n",
    "\n",
    "Please note that the estimated run time of our short notebook is 3 hours. \n",
    "\n",
    "Predictions can be found under: FirstShortNotebook_submission.csv\n",
    "\n",
    "PUBLIC LEADERBOARD SCORE: 0.15111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-05T21:03:59.340186Z",
     "iopub.status.busy": "2021-11-05T21:03:59.339667Z",
     "iopub.status.idle": "2021-11-05T21:04:01.044205Z",
     "shell.execute_reply": "2021-11-05T21:04:01.04333Z",
     "shell.execute_reply.started": "2021-11-05T21:03:59.340151Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "np.random.seed(123)\n",
    "sns.set_style('darkgrid')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "!ln -s /kaggle/input/moscow-housing-tdt4173 ./data\n",
    "!ls ./data | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T21:04:01.955377Z",
     "iopub.status.busy": "2021-11-05T21:04:01.95503Z",
     "iopub.status.idle": "2021-11-05T21:04:01.961656Z",
     "shell.execute_reply": "2021-11-05T21:04:01.960645Z",
     "shell.execute_reply.started": "2021-11-05T21:04:01.955341Z"
    }
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_log_error(y_true, y_pred):\n",
    "    # Alternatively: sklearn.metrics.mean_squared_log_error(y_true, y_pred) ** 0.5\n",
    "    assert (y_true >= 0).all() \n",
    "    assert (y_pred >= 0).all()\n",
    "    log_error = np.log1p(y_pred) - np.log1p(y_true)  # Note: log1p(x) = log(1 + x)\n",
    "    return np.mean(log_error ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T21:04:02.684832Z",
     "iopub.status.busy": "2021-11-05T21:04:02.684337Z",
     "iopub.status.idle": "2021-11-05T21:10:06.786881Z",
     "shell.execute_reply": "2021-11-05T21:10:06.786184Z",
     "shell.execute_reply.started": "2021-11-05T21:04:02.684781Z"
    }
   },
   "outputs": [],
   "source": [
    "#Xgboost 1 PIPELINE  \n",
    "apartments = pd.read_csv('data/apartments_train.csv')\n",
    "buildings = pd.read_csv('data/buildings_train.csv')\n",
    "data = pd.merge(apartments, buildings.set_index('id'), how='left', left_on='building_id', right_index=True)\n",
    "\n",
    "apartments_test = pd.read_csv('data/apartments_test.csv')\n",
    "buildings_test = pd.read_csv('data/buildings_test.csv')\n",
    "data_test = pd.merge(apartments_test, buildings_test.set_index('id'), how='left', left_on='building_id', right_index=True)\n",
    "\n",
    "\n",
    "#Feature Cleaning\n",
    "maxc = 9\n",
    "minc = 1\n",
    "data['ceiling'] = data.apply(lambda row: data[\"ceiling\"].mode()[0] if (row[\"ceiling\"] < minc or row[\"ceiling\"] > maxc ) else( row[\"ceiling\"]) ,axis=1)     \n",
    "data_test['ceiling'] = data_test.apply(lambda row: data[\"ceiling\"].mode()[0] if (row[\"ceiling\"] < minc or row[\"ceiling\"] > maxc ) else( row[\"ceiling\"]) ,axis=1)     \n",
    "\n",
    "\n",
    "var =  4.0\n",
    "data['condition'] = data['condition'].fillna(var)\n",
    "data_test['condition'] = data_test['condition'].fillna(var)\n",
    "\n",
    "\n",
    "data['constructed'] = data.apply(\n",
    "    lambda row: 2019 if (np.isnan(row['constructed']) and ~np.isnan(row['new']) and row['new'] == 0.0) else( 2021 if (np.isnan(row['constructed'])) else row['constructed']),\n",
    "    axis=1\n",
    ")  \n",
    "data['new'] = data.apply(\n",
    "    lambda row: 0.0 if (np.isnan(row['new']) and row['constructed'] < 2020) else( 1.0 if (np.isnan(row['new'])) else row['new']),\n",
    "    axis=1\n",
    ")      \n",
    "\n",
    "data_test['constructed'] = data_test.apply(\n",
    "    lambda row: 2019 if (np.isnan(row['constructed']) and ~np.isnan(row['new']) and row['new'] == 0.0) else( 2021 if (np.isnan(row['constructed'])) else row['constructed']),\n",
    "    axis=1\n",
    ")  \n",
    "data_test['new'] = data_test.apply(\n",
    "    lambda row: 0.0 if (np.isnan(row['new']) and row['constructed'] < 2020) else( 1.0 if (np.isnan(row['new'])) else row['new']),\n",
    "    axis=1\n",
    ")     \n",
    "\n",
    "        \n",
    "for feature in [\"rooms\", \"area_total\", \"area_kitchen\", \"area_living\", \"floor\",\"latitude\", \n",
    "                \"longitude\",\"district\", \"seller\", \"windows_court\", \"balconies\", \"material\", \"stories\"]:\n",
    "    mean = data[feature].mean()\n",
    "    data[feature] = data[feature].fillna(mean)    \n",
    "    data_test[feature] = data_test[feature].fillna(mean)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "#FEATURE ENGINEERING DONE:\n",
    "data['area_total'] = np.log1p(data['area_total'])\n",
    "data['area_kitchen'] = np.log1p(data['area_kitchen'])\n",
    "data['area_living'] = np.log1p(data['area_living'])\n",
    "\n",
    "data_test['area_total'] = np.log1p(data_test['area_total'])\n",
    "data_test['area_kitchen'] = np.log1p(data_test['area_kitchen'])\n",
    "data_test['area_living'] = np.log1p(data_test['area_living'])\n",
    "\n",
    "\n",
    "data['elevatern'] = data.apply(lambda row: 0 if (row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 0.0 ) # \n",
    "                               else( 1 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(2 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(3 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(4 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(5 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(6 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0)\n",
    "                                else(np.nan)\n",
    "                                )   \n",
    "                                )\n",
    "                                )\n",
    "                                )   \n",
    "                                )\n",
    "                                )\n",
    "                                ,axis=1) \n",
    "data_test['elevatern'] = data_test.apply(lambda row: 0 if (row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 0.0 ) # \n",
    "                               else( 1 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(2 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(3 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(4 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(5 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(6 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0)\n",
    "                                else(np.nan)\n",
    "                                )      \n",
    "                                )\n",
    "                                )\n",
    "                                )   \n",
    "                                )\n",
    "                                )\n",
    "                                ,axis=1)  \n",
    "mod = data['elevatern'].mode()\n",
    "data['elevatern'] = data['elevatern'].fillna(mod[0])\n",
    "data_test['elevatern'] = data_test['elevatern'].fillna(mod[0])\n",
    "\n",
    "\n",
    "#Adding city center as origin\n",
    "origin_coordinates = (37.6, 55.75)\n",
    "distance_from_city_center = np.sqrt((origin_coordinates[0] - data[\"longitude\"])**2+(origin_coordinates[1] - data[\"latitude\"])**2)\n",
    "data[\"distance_from_city_center\"] = distance_from_city_center\n",
    "\n",
    "distance_from_city_center_t = np.sqrt((origin_coordinates[0] - data_test[\"longitude\"])**2+(origin_coordinates[1] - data_test[\"latitude\"])**2)\n",
    "data_test[\"distance_from_city_center\"] = distance_from_city_center_t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FEATURES INCLUDED:\n",
    "features = [\"ceiling\", \"rooms\", \"area_total\", \"area_kitchen\", \"area_living\", \"floor\", \"condition\",\"new\", \"elevatern\",\"distance_from_city_center\",\n",
    "            \"latitude\", \"longitude\",\"district\", \"constructed\", \"seller\", \"windows_court\", \"balconies\", \"material\", \"stories\"]\n",
    "\n",
    "\n",
    "\n",
    "#Model\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "train_x = data[features]\n",
    "train_y = np.log1p(data['price'])\n",
    "test_x = data_test[features]\n",
    "\n",
    "    \n",
    "model_xgb1 = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.5144984086781564, gamma=0, learning_rate=0.01693820796093592, max_delta_step=0,\n",
    "       max_depth=23, min_child_weight=5, n_estimators=3977,\n",
    "       n_jobs=1, nthread=None, objective='reg:squarederror', random_state=2020, # squarederror  reg:squaredlogerror   reg:squarederror\n",
    "       reg_alpha=0.021096319890667407, reg_lambda=0.2287729489989326, scale_pos_weight=1, seed=None, subsample=0.42023355655422495)\n",
    "\n",
    "\n",
    "model_xgb1.fit(train_x,train_y)\n",
    "\n",
    "xgb_preds = model_xgb1.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T21:10:06.789469Z",
     "iopub.status.busy": "2021-11-05T21:10:06.788981Z",
     "iopub.status.idle": "2021-11-05T21:11:16.559097Z",
     "shell.execute_reply": "2021-11-05T21:11:16.558145Z",
     "shell.execute_reply.started": "2021-11-05T21:10:06.789428Z"
    }
   },
   "outputs": [],
   "source": [
    "#Catboost PIPELINE  \n",
    "apartments = pd.read_csv('./data/apartments_train.csv')\n",
    "buildings = pd.read_csv('./data/buildings_train.csv')\n",
    "data = pd.merge(apartments, buildings.set_index('id'), how='left', left_on='building_id', right_index=True)\n",
    "\n",
    "apartments_test = pd.read_csv('./data/apartments_test.csv')\n",
    "buildings_test = pd.read_csv('./data/buildings_test.csv')\n",
    "data_test = pd.merge(apartments_test, buildings_test.set_index('id'), how='left', left_on='building_id', right_index=True)\n",
    "\n",
    "\n",
    "#FEATURE CLEANING:\n",
    "for feature in [\"ceiling\",\"rooms\", \"area_total\", \"area_kitchen\", \"area_living\", \"floor\", \"condition\",\"new\",\n",
    "            \"latitude\", \"longitude\",\"district\", \"constructed\", \"seller\", \"balconies\", \"material\", \"stories\"]:\n",
    "        if data[feature].max() == 1.0 or feature == \"elevator_service\" or feature == \"condition\" or feature == \"constructed\" or feature == \"material\" or feature == \"seller\" :\n",
    "            #print('Categorical',feature)\n",
    "            mod = data[feature].mode()\n",
    "            data[feature] = data[feature].fillna(mod[0])\n",
    "            \n",
    "            mod_t = data_test[feature].mode()\n",
    "            data_test[feature] = data_test[feature].fillna(mod_t[0])          \n",
    "        else:\n",
    "            mean = data[feature].mean()\n",
    "            data[feature] = data[feature].fillna(mean)\n",
    "            \n",
    "            mean_t = data_test[feature].mean()\n",
    "            data_test[feature] = data_test[feature].fillna(mean_t)\n",
    "\n",
    "\n",
    "\n",
    "#FEATURE ENGINEERING:\n",
    "origin_coordinates = (37.6, 55.75)\n",
    "distance_from_city_center = np.sqrt((origin_coordinates[0] - data[\"longitude\"])**2+(origin_coordinates[1] - data[\"latitude\"])**2)\n",
    "data[\"distance_from_city_center\"] = distance_from_city_center\n",
    "\n",
    "distance_from_city_center_t = np.sqrt((origin_coordinates[0] - data_test[\"longitude\"])**2+(origin_coordinates[1] - data_test[\"latitude\"])**2)\n",
    "data_test[\"distance_from_city_center\"] = distance_from_city_center_t\n",
    "\n",
    "#FEATURES INCLUDED:\n",
    "features = [\"ceiling\",\"rooms\", \"area_total\", \"area_kitchen\", \"area_living\", \"floor\", \"condition\",\"new\",\n",
    "            \"latitude\", \"longitude\",\"district\", \"constructed\", \"seller\", \"balconies\", \"material\", \"stories\", \"distance_from_city_center\"]\n",
    "\n",
    "\n",
    "#Model\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "train_x = data[features]\n",
    "train_y = np.log1p(data['price'])\n",
    "test_x = data_test[features]\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "param = {\n",
    "\"objective\": \"RMSE\",\n",
    "'random_state': 2020, \n",
    "'learning_rate': 0.027775682386650822, \n",
    "'n_estimators': 9561, \n",
    "'reg_lambda': 0.02942773134248745, \n",
    "'subsample': 0.6452052083779029,\n",
    "'depth': 8,\n",
    "'bagging_temperature': 56.77037557663241}\n",
    "\n",
    "\n",
    "model_cat2 = CatBoostRegressor(**param)  \n",
    "\n",
    "model_cat2.fit(train_x,train_y,early_stopping_rounds=100,verbose=False)\n",
    "\n",
    "catboost2_preds = model_cat2.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T21:11:16.56139Z",
     "iopub.status.busy": "2021-11-05T21:11:16.560907Z",
     "iopub.status.idle": "2021-11-05T21:12:10.594247Z",
     "shell.execute_reply": "2021-11-05T21:12:10.593291Z",
     "shell.execute_reply.started": "2021-11-05T21:11:16.561344Z"
    }
   },
   "outputs": [],
   "source": [
    "#LGBM 2 PIPELINE\n",
    "apartments = pd.read_csv('data/apartments_train.csv')\n",
    "buildings = pd.read_csv('data/buildings_train.csv')\n",
    "data = pd.merge(apartments, buildings.set_index('id'), how='left', left_on='building_id', right_index=True)\n",
    "\n",
    "apartments_test = pd.read_csv('data/apartments_test.csv')\n",
    "buildings_test = pd.read_csv('data/buildings_test.csv')\n",
    "data_test = pd.merge(apartments_test, buildings_test.set_index('id'), how='left', left_on='building_id', right_index=True)\n",
    "\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "import pyproj\n",
    "from numpy.random import choice\n",
    "\n",
    "\n",
    "#FEATURE CLEANING\n",
    "data_test.latitude.iloc[90] = 55.568139\n",
    "data_test.longitude.iloc[90]= 37.481831\n",
    "data_test.latitude.iloc[23] = 55.568139\n",
    "data_test.longitude.iloc[23]= 37.481831\n",
    "data_test.latitude.iloc[2511] = 55.544066\n",
    "data_test.longitude.iloc[2511]= 37.482317\n",
    "data_test.latitude.iloc[6959] = 55.544066\n",
    "data_test.longitude.iloc[6959]= 37.482317\n",
    "data_test.latitude.iloc[5090] = 55.544066\n",
    "data_test.longitude.iloc[5090]= 37.482317\n",
    "data_test.latitude.iloc[8596] = 55.544066\n",
    "data_test.longitude.iloc[8596]= 37.482317\n",
    "data_test.latitude.iloc[2529] = 55.764335\n",
    "data_test.longitude.iloc[2529]= 37.907556\n",
    "data_test.latitude.iloc[4719] = 55.765430\n",
    "data_test.longitude.iloc[4719]= 37.928284\n",
    "data_test.latitude.iloc[9547] = 55.765430\n",
    "data_test.longitude.iloc[9547]= 37.928284\n",
    "\n",
    "data_test.district[data_test.building_id == 3803] = 11\n",
    "data_test.district[data_test.building_id == 4636] = 11\n",
    "data_test.district[data_test.building_id == 4412] = 11\n",
    "data_test.district[data_test.building_id == 926] = 3\n",
    "data_test.district[data_test.building_id == 4202] = 3\n",
    "data_test.district[data_test.building_id == 8811] = 3\n",
    "data_test.district[data_test.building_id == 6879] = 3\n",
    "data_test.district[data_test.building_id == 5667] = 3\n",
    "data_test.district[data_test.building_id == 2265] = 5\n",
    "data_test.district[data_test.building_id == 6403] = 5\n",
    "data_test.district[data_test.building_id == 7317] = 5\n",
    "data_test.district[data_test.building_id == 1647] = 5\n",
    "data_test.district[data_test.building_id == 183] = 5\n",
    "\n",
    "data.district[data.building_id == 2029] = 0\n",
    "data.district[data.building_id == 1255] = 0\n",
    "data.district[data.building_id == 4162] = 5\n",
    "\n",
    "\n",
    "#cleaning/engineering all elevators as one feature\n",
    "data['elevatern'] = data.apply(lambda row: 0 if (row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 0.0 ) # \n",
    "                               else( 1 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(2 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(3 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(4 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(5 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(6 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0)\n",
    "                                else(np.nan)\n",
    "                                )    \n",
    "                                )\n",
    "                                )\n",
    "                                )   \n",
    "                                )\n",
    "                                )\n",
    "                                ,axis=1)\n",
    "data_test['elevatern'] = data_test.apply(lambda row: 0 if (row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 0.0 ) # \n",
    "                               else( 1 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(2 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(3 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(4 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(5 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(6 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0)\n",
    "                                else(np.nan)\n",
    "                                ) \n",
    "                                )\n",
    "                                )\n",
    "                                )   \n",
    "                                )\n",
    "                                )\n",
    "                                ,axis=1)  \n",
    "mod = data['elevatern'].mode()\n",
    "data['elevatern'] = data['elevatern'].fillna(mod[0])\n",
    "data_test['elevatern'] = data_test['elevatern'].fillna(mod[0])\n",
    "\n",
    "\n",
    "data[\"bathrooms_shared\"] = data[\"bathrooms_shared\"].fillna(1)\n",
    "data[\"bathrooms_private\"] = data[\"bathrooms_private\"].fillna(1)\n",
    "data_test[\"bathrooms_shared\"] = data_test[\"bathrooms_shared\"].fillna(1)\n",
    "data_test[\"bathrooms_private\"] = data_test[\"bathrooms_private\"].fillna(1)\n",
    "\n",
    "\n",
    "\n",
    "data[\"parking\"] =  data[\"parking\"].fillna(3.0)\n",
    "data_test[\"parking\"] =  data_test[\"parking\"].fillna(3.0)\n",
    "data[\"heating\"] =  data[\"heating\"].fillna(0.0)\n",
    "data_test[\"heating\"] =  data_test[\"heating\"].fillna(0.0)\n",
    "\n",
    "#engineering and cleaning a feature\n",
    "data[\"total_balconies\"] = data[\"balconies\"] + data[\"loggias\"]\n",
    "data_test[\"total_balconies\"] = data_test[\"balconies\"] + data_test[\"loggias\"]\n",
    "data[\"total_balconies\"] =  data[\"total_balconies\"].fillna(1.0)\n",
    "data_test[\"total_balconies\"] =  data_test[\"total_balconies\"].fillna(1.0)\n",
    "\n",
    "\n",
    "#seller\n",
    "list_of_candidates = [0,1,2,3]\n",
    "probability_distribution  = [0.11, 0.33, 0.13, 0.43]\n",
    "number_of_items_to_pick = data['seller'].isna().sum()\n",
    "number_of_items_to_pick_test = data_test['seller'].isna().sum()\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "draw = choice(list_of_candidates, number_of_items_to_pick,\n",
    "              p=probability_distribution)\n",
    "draw_test = choice(list_of_candidates, number_of_items_to_pick_test,\n",
    "              p=probability_distribution)\n",
    "\n",
    "data['seller'][data.seller.isna()] = draw\n",
    "data_test['seller'][data_test.seller.isna()] = draw_test\n",
    "\n",
    "\n",
    "#area_kitchen and living\n",
    "percentage_area_data = pd.DataFrame()\n",
    "percentage_area_data[\"area_kitchen\"] = data[\"area_kitchen\"][data.area_living + data.area_kitchen < data.area_total]/data[\"area_total\"][data.area_living + data.area_kitchen < data.area_total]\n",
    "percentage_area_data[\"area_living\"] = data[\"area_living\"][data.area_living + data.area_kitchen < data.area_total]/data[\"area_total\"][data.area_living + data.area_kitchen < data.area_total]\n",
    "\n",
    "mean_kitchen = percentage_area_data[\"area_kitchen\"].mean()\n",
    "mean_living = percentage_area_data[\"area_living\"].mean()\n",
    "\n",
    "#to omit bugs\n",
    "data[\"area_kitchen_edit\"] = data[\"area_kitchen\"].copy()\n",
    "data[\"area_living_edit\"] = data[\"area_living\"].copy()\n",
    "\n",
    "data[\"area_kitchen_edit\"][(data.area_living + data.area_kitchen >= data.area_total) | (data.area_living.isna() | data.area_kitchen.isna())] = data.area_total*mean_kitchen\n",
    "data[\"area_living_edit\"][(data.area_living + data.area_kitchen >= data.area_total) | (data.area_living.isna() | data.area_kitchen.isna())] = data.area_total*mean_living\n",
    "\n",
    "data[\"area_kitchen\"] = data[\"area_kitchen_edit\"].copy()\n",
    "data[\"area_living\"] = data[\"area_living_edit\"].copy()\n",
    "\n",
    "#test_set\n",
    "data_test[\"area_kitchen_edit\"] = data_test[\"area_kitchen\"].copy()\n",
    "data_test[\"area_living_edit\"] = data_test[\"area_living\"].copy()\n",
    "\n",
    "data_test[\"area_kitchen_edit\"][(data_test.area_living + data_test.area_kitchen >= data_test.area_total) | (data_test.area_living.isna() | data_test.area_kitchen.isna())] = data_test.area_total*mean_kitchen\n",
    "data_test[\"area_living_edit\"][(data_test.area_living + data_test.area_kitchen >= data_test.area_total) | (data_test.area_living.isna() | data_test.area_kitchen.isna())] = data_test.area_total*mean_living\n",
    "\n",
    "\n",
    "data_test[\"area_kitchen\"] = data_test[\"area_kitchen_edit\"].copy()\n",
    "data_test[\"area_living\"] = data_test[\"area_living_edit\"].copy()\n",
    "        \n",
    "\n",
    "#ceiling    \n",
    "maxc = 9\n",
    "minc = 1\n",
    "data['ceiling'] = data.apply(lambda row: data[\"ceiling\"].mode()[0] if (row[\"ceiling\"] < minc or row[\"ceiling\"] > maxc ) else( row[\"ceiling\"]) ,axis=1) \n",
    "data_test['ceiling'] = data_test.apply(lambda row: data[\"ceiling\"].mode()[0] if (row[\"ceiling\"] < minc or row[\"ceiling\"] > maxc ) else( row[\"ceiling\"]) ,axis=1)  \n",
    "\n",
    "data['ceiling'][data.ceiling.isna() ] = data[\"ceiling\"].mode()[0]\n",
    "data_test['ceiling'][data_test.ceiling.isna() ] = data[\"ceiling\"].mode()[0]\n",
    "\n",
    "\n",
    "#condition\n",
    "var =  4.0\n",
    "data['condition'] = data['condition'].fillna(var)\n",
    "data_test['condition'] = data_test['condition'].fillna(var)\n",
    "\n",
    "\n",
    "#stories\n",
    "idss = data[[\"building_id\"]][data.floor > data.stories].sort_values(\"building_id\").drop_duplicates()\n",
    "for i in range(idss.size):\n",
    "    max_floor = data['floor'][data[\"building_id\"] == idss[\"building_id\"].iloc[i]].max()\n",
    "    data['stories'][data[\"building_id\"] == idss[\"building_id\"].iloc[i]] =  max_floor\n",
    "\n",
    "idss_test = data_test[[\"building_id\"]][data_test.floor > data_test.stories].sort_values(\"building_id\").drop_duplicates()\n",
    "for i in range(idss_test.size):\n",
    "    max_floor_test = data_test['floor'][data_test[\"building_id\"] == idss_test[\"building_id\"].iloc[i]].max()\n",
    "    data_test['stories'][data_test[\"building_id\"] == idss_test[\"building_id\"].iloc[i]] =  max_floor_test\n",
    "\n",
    "\n",
    "#material\n",
    "data.material[data.material==5] = 2.0 #merging monlith brick with monolith\n",
    "data.material[data.material==6] = 5.0 #stalin to 5\n",
    "\n",
    "data_test.material[data_test.material==5] = 2.0\n",
    "data_test.material[data_test.material==6] = 5.0\n",
    "\n",
    "data['material'][data.material.isna() ] = data['material'].mode()[0]\n",
    "data_test['material'][data_test.material.isna() ] = data['material'].mode()[0]\n",
    "\n",
    "#constructed, new:\n",
    "data['constructed'] = data.apply(\n",
    "    lambda row: 2019 if (np.isnan(row['constructed']) and ~np.isnan(row['new']) and row['new'] == 0.0) else( 2021 if (np.isnan(row['constructed'])) else row['constructed']),\n",
    "    axis=1\n",
    ")  \n",
    "data['new'] = data.apply(\n",
    "    lambda row: 0.0 if (np.isnan(row['new']) and row['constructed'] < 2020) else( 1.0 if (np.isnan(row['new'])) else row['new']),\n",
    "    axis=1\n",
    ")      \n",
    "\n",
    "\n",
    "data_test['constructed'] = data_test.apply(\n",
    "    lambda row: 2019 if (np.isnan(row['constructed']) and ~np.isnan(row['new']) and row['new'] == 0.0) else( 2021 if (np.isnan(row['constructed'])) else row['constructed']),\n",
    "    axis=1\n",
    ")  \n",
    "data_test['new'] = data_test.apply(\n",
    "    lambda row: 0.0 if (np.isnan(row['new']) and row['constructed'] < 2020) else( 1.0 if (np.isnan(row['new'])) else row['new']),\n",
    "    axis=1\n",
    ")  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FEATURE ENGINEERING:\n",
    "\n",
    "lon1 =  37.621390\n",
    "lat1 = 55.753098\n",
    "geodesic = pyproj.Geod(ellps='WGS84')\n",
    "distance_arr = []\n",
    "back_azimuth_arr = []\n",
    "fwd_azimuth_arr = []\n",
    "for i in range(len(data[\"longitude\"])):\n",
    "    fwd_azimuth,back_azimuth,distance = geodesic.inv(lon1, lat1, data[\"longitude\"][i], data[\"latitude\"][i])\n",
    "    distance_arr.append(distance)\n",
    "    back_azimuth_arr.append(back_azimuth)\n",
    "    fwd_azimuth_arr.append(fwd_azimuth)\n",
    "\n",
    "data['fwd_azi'] = fwd_azimuth_arr\n",
    "data['distance'] = distance_arr\n",
    "data['back_azi'] = back_azimuth_arr\n",
    "\n",
    "\n",
    "geodesic = pyproj.Geod(ellps='WGS84')\n",
    "distance_arr = []\n",
    "back_azimuth_arr = []\n",
    "fwd_azimuth_arr = []\n",
    "for i in range(len(data_test[\"longitude\"])):\n",
    "    fwd_azimuth,back_azimuth,distance = geodesic.inv(lon1, lat1, data_test[\"longitude\"][i], data_test[\"latitude\"][i])\n",
    "    distance_arr.append(distance)\n",
    "    back_azimuth_arr.append(back_azimuth)\n",
    "    fwd_azimuth_arr.append(fwd_azimuth)\n",
    "\n",
    "data_test['fwd_azi'] = fwd_azimuth_arr\n",
    "data_test['distance'] = distance_arr\n",
    "data_test['back_azi'] = back_azimuth_arr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data['area_per_room'] = data['area_total']/data['rooms']\n",
    "data_test['area_per_room'] = data_test['area_total']/data_test['rooms']\n",
    "\n",
    "data['area_per_room_log'] = np.log1p(data['area_per_room'])\n",
    "data_test['area_per_room_log'] = np.log1p(data_test['area_per_room'])\n",
    "\n",
    "data['area_total_log'] = np.log1p(data['area_total'])\n",
    "data['area_kitchen_log'] = np.log1p(data['area_kitchen'])\n",
    "data['area_living_log'] = np.log1p(data['area_living'])\n",
    "\n",
    "data_test['area_total_log'] = np.log1p(data_test['area_total'])\n",
    "data_test['area_kitchen_log'] = np.log1p(data_test['area_kitchen'])\n",
    "data_test['area_living_log'] = np.log1p(data_test['area_living'])\n",
    "\n",
    "\n",
    "data[\"bathrooms_total\"] = data.bathrooms_shared + data.bathrooms_private\n",
    "data_test[\"bathrooms_total\"] = data_test.bathrooms_shared + data_test.bathrooms_private\n",
    "\n",
    "\n",
    "\n",
    "#FEATURES INCLUDED:\n",
    "features = [\"ceiling\", \"area_per_room\" ,  \"area_per_room_log\", \"rooms\", \"area_total\", \"area_kitchen\", \"area_living\", \"area_total_log\", \"area_kitchen_log\", \"area_living_log\", \"floor\", \"new\", \"elevatern\", \"bathrooms_total\", \"bathrooms_shared\", \"bathrooms_private\", 'parking', 'heating',\n",
    "            \"latitude\", \"longitude\",\"district\", \"constructed\", \"condition\", \"seller\", \"total_balconies\", \"material\", \"stories\",'distance','back_azi','fwd_azi']\n",
    "\n",
    "    \n",
    "#Model\n",
    "train_x = data[features]\n",
    "train_y = np.log1p(data['price']/data[\"area_total\"])\n",
    "test_x = data_test[features]\n",
    "\n",
    "\n",
    "\n",
    "param = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 35,\n",
    "            'min_child_weight': 1,\n",
    "            'subsample': 0.32415121173658534,\n",
    "            'colsample_bytree':  0.4768205472451884,\n",
    "            'reg_lambda': 0.14916991373512928,\n",
    "            'reg_alpha': 0.006696476138868112,\n",
    "            'learning_rate': 0.01747572661694792,\n",
    "            'max_depth': 46,\n",
    "            'n_estimators': 9775,\n",
    "            'n_jobs' : 1,\n",
    "            'objective' : 'regression',\n",
    "\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "model_lgbm2 = LGBMRegressor(**param)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_lgbm2.fit(train_x,train_y)\n",
    "\n",
    "lgbm2_preds = model_lgbm2.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-05T21:12:10.596543Z",
     "iopub.status.busy": "2021-11-05T21:12:10.596307Z",
     "iopub.status.idle": "2021-11-05T21:15:13.864382Z",
     "shell.execute_reply": "2021-11-05T21:15:13.863557Z",
     "shell.execute_reply.started": "2021-11-05T21:12:10.596492Z"
    }
   },
   "outputs": [],
   "source": [
    "#Xgb2 Pipeline\n",
    "train_x = data[features]\n",
    "train_y = np.log1p(data['price']/data[\"area_total\"])\n",
    "test_x = data_test[features]\n",
    "\n",
    "model_xgb2 = XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "colsample_bytree=0.5728285533310635, gamma=0, learning_rate=0.016003653491882115, max_delta_step=0,\n",
    "max_depth=8, min_child_weight=1, n_estimators=3515,\n",
    "n_jobs=1, nthread=None, objective='reg:squarederror', random_state=5, # squarederror reg:squaredlogerror reg:squarederror\n",
    "reg_alpha=0.005800171239325761, reg_lambda=0.48110648627756064, scale_pos_weight=1, seed=None, subsample=0.7155884414918227)\n",
    "\n",
    "\n",
    "model_xgb2.fit(train_x,train_y)\n",
    "\n",
    "xgb2_preds = model_xgb2.predict(test_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB3 (0.15178) on its own\n",
    "apartments = pd.read_csv('data/apartments_train.csv')\n",
    "buildings = pd.read_csv('data/buildings_train.csv')\n",
    "data = pd.merge(apartments, buildings.set_index('id'), how='left', left_on='building_id', right_index=True)\n",
    "\n",
    "apartments_test = pd.read_csv('data/apartments_test.csv')\n",
    "buildings_test = pd.read_csv('data/buildings_test.csv')\n",
    "data_test = pd.merge(apartments_test, buildings_test.set_index('id'), how='left', left_on='building_id', right_index=True)\n",
    "\n",
    "\n",
    "\n",
    "import pyproj\n",
    "from numpy.random import choice\n",
    "\n",
    "\n",
    "#FEATURE CLEANING\n",
    "data_test.latitude.iloc[90] = 55.568139\n",
    "data_test.longitude.iloc[90]= 37.481831\n",
    "data_test.latitude.iloc[23] = 55.568139\n",
    "data_test.longitude.iloc[23]= 37.481831\n",
    "data_test.latitude.iloc[2511] = 55.544066\n",
    "data_test.longitude.iloc[2511]= 37.482317\n",
    "data_test.latitude.iloc[6959] = 55.544066\n",
    "data_test.longitude.iloc[6959]= 37.482317\n",
    "data_test.latitude.iloc[5090] = 55.544066\n",
    "data_test.longitude.iloc[5090]= 37.482317\n",
    "data_test.latitude.iloc[8596] = 55.544066\n",
    "data_test.longitude.iloc[8596]= 37.482317\n",
    "data_test.latitude.iloc[2529] = 55.764335\n",
    "data_test.longitude.iloc[2529]= 37.907556\n",
    "data_test.latitude.iloc[4719] = 55.765430\n",
    "data_test.longitude.iloc[4719]= 37.928284\n",
    "data_test.latitude.iloc[9547] = 55.765430\n",
    "data_test.longitude.iloc[9547]= 37.928284\n",
    "\n",
    "data_test.district[data_test.building_id == 3803] = 11\n",
    "data_test.district[data_test.building_id == 4636] = 11\n",
    "data_test.district[data_test.building_id == 4412] = 11\n",
    "data_test.district[data_test.building_id == 926] = 3\n",
    "data_test.district[data_test.building_id == 4202] = 3\n",
    "data_test.district[data_test.building_id == 8811] = 3\n",
    "data_test.district[data_test.building_id == 6879] = 3\n",
    "data_test.district[data_test.building_id == 5667] = 3\n",
    "data_test.district[data_test.building_id == 2265] = 5\n",
    "data_test.district[data_test.building_id == 6403] = 5\n",
    "data_test.district[data_test.building_id == 7317] = 5\n",
    "data_test.district[data_test.building_id == 1647] = 5\n",
    "data_test.district[data_test.building_id == 183] = 5\n",
    "\n",
    "data.district[data.building_id == 2029] = 0\n",
    "data.district[data.building_id == 1255] = 0\n",
    "data.district[data.building_id == 4162] = 5\n",
    "\n",
    "\n",
    "#cleaning/engineering all elevators as one feature\n",
    "data['elevatern'] = data.apply(lambda row: 0 if (row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 0.0 ) # \n",
    "                               else( 1 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(2 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(3 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(4 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(5 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(6 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0)\n",
    "                                else(np.nan)\n",
    "                                )    \n",
    "                                )\n",
    "                                )\n",
    "                                )   \n",
    "                                )\n",
    "                                )\n",
    "                                ,axis=1)\n",
    "data_test['elevatern'] = data_test.apply(lambda row: 0 if (row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 0.0 ) # \n",
    "                               else( 1 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(2 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(3 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(4 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(5 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(6 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0)\n",
    "                                else(np.nan)\n",
    "                                ) \n",
    "                                )\n",
    "                                )\n",
    "                                )   \n",
    "                                )\n",
    "                                )\n",
    "                                ,axis=1)  \n",
    "mod = data['elevatern'].mode()\n",
    "data['elevatern'] = data['elevatern'].fillna(mod[0])\n",
    "data_test['elevatern'] = data_test['elevatern'].fillna(mod[0])\n",
    "\n",
    "\n",
    "data[\"bathrooms_shared\"] = data[\"bathrooms_shared\"].fillna(1)\n",
    "data[\"bathrooms_private\"] = data[\"bathrooms_private\"].fillna(1)\n",
    "data_test[\"bathrooms_shared\"] = data_test[\"bathrooms_shared\"].fillna(1)\n",
    "data_test[\"bathrooms_private\"] = data_test[\"bathrooms_private\"].fillna(1)\n",
    "\n",
    "\n",
    "\n",
    "data[\"parking\"] =  data[\"parking\"].fillna(3.0)\n",
    "data_test[\"parking\"] =  data_test[\"parking\"].fillna(3.0)\n",
    "data[\"heating\"] =  data[\"heating\"].fillna(0.0)\n",
    "data_test[\"heating\"] =  data_test[\"heating\"].fillna(0.0)\n",
    "\n",
    "#engineering and cleaning a feature\n",
    "data[\"total_balconies\"] = data[\"balconies\"] + data[\"loggias\"]\n",
    "data_test[\"total_balconies\"] = data_test[\"balconies\"] + data_test[\"loggias\"]\n",
    "data[\"total_balconies\"] =  data[\"total_balconies\"].fillna(1.0)\n",
    "data_test[\"total_balconies\"] =  data_test[\"total_balconies\"].fillna(1.0)\n",
    "\n",
    "\n",
    "#seller\n",
    "list_of_candidates = [0,1,2,3]\n",
    "probability_distribution  = [0.11, 0.33, 0.13, 0.43]\n",
    "number_of_items_to_pick = data['seller'].isna().sum()\n",
    "number_of_items_to_pick_test = data_test['seller'].isna().sum()\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "draw = choice(list_of_candidates, number_of_items_to_pick,\n",
    "              p=probability_distribution)\n",
    "draw_test = choice(list_of_candidates, number_of_items_to_pick_test,\n",
    "              p=probability_distribution)\n",
    "\n",
    "data['seller'][data.seller.isna()] = draw\n",
    "data_test['seller'][data_test.seller.isna()] = draw_test\n",
    "\n",
    "\n",
    "#area_kitchen and living\n",
    "percentage_area_data = pd.DataFrame()\n",
    "percentage_area_data[\"area_kitchen\"] = data[\"area_kitchen\"][data.area_living + data.area_kitchen < data.area_total]/data[\"area_total\"][data.area_living + data.area_kitchen < data.area_total]\n",
    "percentage_area_data[\"area_living\"] = data[\"area_living\"][data.area_living + data.area_kitchen < data.area_total]/data[\"area_total\"][data.area_living + data.area_kitchen < data.area_total]\n",
    "\n",
    "mean_kitchen = percentage_area_data[\"area_kitchen\"].mean()\n",
    "mean_living = percentage_area_data[\"area_living\"].mean()\n",
    "\n",
    "#to omit bugs\n",
    "data[\"area_kitchen_edit\"] = data[\"area_kitchen\"].copy()\n",
    "data[\"area_living_edit\"] = data[\"area_living\"].copy()\n",
    "\n",
    "data[\"area_kitchen_edit\"][(data.area_living + data.area_kitchen >= data.area_total) | (data.area_living.isna() | data.area_kitchen.isna())] = data.area_total*mean_kitchen\n",
    "data[\"area_living_edit\"][(data.area_living + data.area_kitchen >= data.area_total) | (data.area_living.isna() | data.area_kitchen.isna())] = data.area_total*mean_living\n",
    "\n",
    "data[\"area_kitchen\"] = data[\"area_kitchen_edit\"].copy()\n",
    "data[\"area_living\"] = data[\"area_living_edit\"].copy()\n",
    "\n",
    "#test_set\n",
    "data_test[\"area_kitchen_edit\"] = data_test[\"area_kitchen\"].copy()\n",
    "data_test[\"area_living_edit\"] = data_test[\"area_living\"].copy()\n",
    "\n",
    "data_test[\"area_kitchen_edit\"][(data_test.area_living + data_test.area_kitchen >= data_test.area_total) | (data_test.area_living.isna() | data_test.area_kitchen.isna())] = data_test.area_total*mean_kitchen\n",
    "data_test[\"area_living_edit\"][(data_test.area_living + data_test.area_kitchen >= data_test.area_total) | (data_test.area_living.isna() | data_test.area_kitchen.isna())] = data_test.area_total*mean_living\n",
    "\n",
    "\n",
    "data_test[\"area_kitchen\"] = data_test[\"area_kitchen_edit\"].copy()\n",
    "data_test[\"area_living\"] = data_test[\"area_living_edit\"].copy()\n",
    "        \n",
    "\n",
    "#ceiling    \n",
    "maxc = 9\n",
    "minc = 1\n",
    "data['ceiling'] = data.apply(lambda row: data[\"ceiling\"].mode()[0] if (row[\"ceiling\"] < minc or row[\"ceiling\"] > maxc ) else( row[\"ceiling\"]) ,axis=1) \n",
    "data_test['ceiling'] = data_test.apply(lambda row: data[\"ceiling\"].mode()[0] if (row[\"ceiling\"] < minc or row[\"ceiling\"] > maxc ) else( row[\"ceiling\"]) ,axis=1)  \n",
    "\n",
    "data['ceiling'][data.ceiling.isna() ] = data[\"ceiling\"].mode()[0]\n",
    "data_test['ceiling'][data_test.ceiling.isna() ] = data[\"ceiling\"].mode()[0]\n",
    "\n",
    "\n",
    "#condition\n",
    "var =  4.0\n",
    "data['condition'] = data['condition'].fillna(var)\n",
    "data_test['condition'] = data_test['condition'].fillna(var)\n",
    "\n",
    "\n",
    "#stories\n",
    "idss = data[[\"building_id\"]][data.floor > data.stories].sort_values(\"building_id\").drop_duplicates()\n",
    "for i in range(idss.size):\n",
    "    max_floor = data['floor'][data[\"building_id\"] == idss[\"building_id\"].iloc[i]].max()\n",
    "    data['stories'][data[\"building_id\"] == idss[\"building_id\"].iloc[i]] =  max_floor\n",
    "\n",
    "idss_test = data_test[[\"building_id\"]][data_test.floor > data_test.stories].sort_values(\"building_id\").drop_duplicates()\n",
    "for i in range(idss_test.size):\n",
    "    max_floor_test = data_test['floor'][data_test[\"building_id\"] == idss_test[\"building_id\"].iloc[i]].max()\n",
    "    data_test['stories'][data_test[\"building_id\"] == idss_test[\"building_id\"].iloc[i]] =  max_floor_test\n",
    "\n",
    "\n",
    "#material\n",
    "data.material[data.material==5] = 2.0 #merging monlith brick with monolith\n",
    "data.material[data.material==6] = 5.0 #stalin to 5\n",
    "\n",
    "data_test.material[data_test.material==5] = 2.0\n",
    "data_test.material[data_test.material==6] = 5.0\n",
    "\n",
    "data['material'][data.material.isna() ] = data['material'].mode()[0]\n",
    "data_test['material'][data_test.material.isna() ] = data['material'].mode()[0]\n",
    "\n",
    "#constructed, new:\n",
    "data['constructed'] = data.apply(\n",
    "    lambda row: 2019 if (np.isnan(row['constructed']) and ~np.isnan(row['new']) and row['new'] == 0.0) else( 2021 if (np.isnan(row['constructed'])) else row['constructed']),\n",
    "    axis=1\n",
    ")  \n",
    "data['new'] = data.apply(\n",
    "    lambda row: 0.0 if (np.isnan(row['new']) and row['constructed'] < 2020) else( 1.0 if (np.isnan(row['new'])) else row['new']),\n",
    "    axis=1\n",
    ")      \n",
    "\n",
    "\n",
    "data_test['constructed'] = data_test.apply(\n",
    "    lambda row: 2019 if (np.isnan(row['constructed']) and ~np.isnan(row['new']) and row['new'] == 0.0) else( 2021 if (np.isnan(row['constructed'])) else row['constructed']),\n",
    "    axis=1\n",
    ")  \n",
    "data_test['new'] = data_test.apply(\n",
    "    lambda row: 0.0 if (np.isnan(row['new']) and row['constructed'] < 2020) else( 1.0 if (np.isnan(row['new'])) else row['new']),\n",
    "    axis=1\n",
    ")  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FEATURE ENGINEERING:\n",
    "\n",
    "lon1 =  37.621390\n",
    "lat1 = 55.753098\n",
    "geodesic = pyproj.Geod(ellps='WGS84')\n",
    "distance_arr = []\n",
    "back_azimuth_arr = []\n",
    "fwd_azimuth_arr = []\n",
    "for i in range(len(data[\"longitude\"])):\n",
    "    fwd_azimuth,back_azimuth,distance = geodesic.inv(lon1, lat1, data[\"longitude\"][i], data[\"latitude\"][i])\n",
    "    distance_arr.append(distance)\n",
    "    back_azimuth_arr.append(back_azimuth)\n",
    "    fwd_azimuth_arr.append(fwd_azimuth)\n",
    "\n",
    "data['fwd_azi'] = fwd_azimuth_arr\n",
    "data['distance'] = distance_arr\n",
    "data['back_azi'] = back_azimuth_arr\n",
    "\n",
    "\n",
    "geodesic = pyproj.Geod(ellps='WGS84')\n",
    "distance_arr = []\n",
    "back_azimuth_arr = []\n",
    "fwd_azimuth_arr = []\n",
    "for i in range(len(data_test[\"longitude\"])):\n",
    "    fwd_azimuth,back_azimuth,distance = geodesic.inv(lon1, lat1, data_test[\"longitude\"][i], data_test[\"latitude\"][i])\n",
    "    distance_arr.append(distance)\n",
    "    back_azimuth_arr.append(back_azimuth)\n",
    "    fwd_azimuth_arr.append(fwd_azimuth)\n",
    "\n",
    "data_test['fwd_azi'] = fwd_azimuth_arr\n",
    "data_test['distance'] = distance_arr\n",
    "data_test['back_azi'] = back_azimuth_arr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data['area_per_room'] = data['area_total']/data['rooms']\n",
    "data_test['area_per_room'] = data_test['area_total']/data_test['rooms']\n",
    "\n",
    "data['area_per_room_log'] = np.log1p(data['area_per_room'])\n",
    "data_test['area_per_room_log'] = np.log1p(data_test['area_per_room'])\n",
    "\n",
    "data['area_total_log'] = np.log1p(data['area_total'])\n",
    "data['area_kitchen_log'] = np.log1p(data['area_kitchen'])\n",
    "data['area_living_log'] = np.log1p(data['area_living'])\n",
    "\n",
    "data_test['area_total_log'] = np.log1p(data_test['area_total'])\n",
    "data_test['area_kitchen_log'] = np.log1p(data_test['area_kitchen'])\n",
    "data_test['area_living_log'] = np.log1p(data_test['area_living'])\n",
    "\n",
    "\n",
    "data[\"bathrooms_total\"] = data.bathrooms_shared + data.bathrooms_private\n",
    "data_test[\"bathrooms_total\"] = data_test.bathrooms_shared + data_test.bathrooms_private\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#floor/stories\n",
    "data[\"floor/stories\"] = data[\"floor\"]/data[\"stories\"]\n",
    "data_test[\"floor/stories\"] = data_test[\"floor\"]/data_test[\"stories\"]\n",
    "\n",
    "\n",
    "#euclidean financial distance from city center\n",
    "financial_coords = (37.535497858, 55.741330368)\n",
    "distance_from_city_center = np.sqrt((financial_coords[0] - data[\"longitude\"])**2+(financial_coords[1] - data[\"latitude\"])**2)\n",
    "data[\"distance_from_financial_center\"] = distance_from_city_center\n",
    "\n",
    "distance_from_city_center_t = np.sqrt((financial_coords[0] - data_test[\"longitude\"])**2+(financial_coords[1] - data_test[\"latitude\"])**2)\n",
    "data_test[\"distance_from_financial_center\"] = distance_from_city_center_t\n",
    "\n",
    "\n",
    "#euclidean distance from city center\n",
    "origin_coordinates = (37.621390,55.753098)\n",
    "distance_from_city_center = np.sqrt((origin_coordinates[0] - data[\"longitude\"])**2+(origin_coordinates[1] - data[\"latitude\"])**2)\n",
    "data[\"distance_from_city_center\"] = distance_from_city_center\n",
    "\n",
    "distance_from_city_center_t = np.sqrt((origin_coordinates[0] - data_test[\"longitude\"])**2+(origin_coordinates[1] - data_test[\"latitude\"])**2)\n",
    "data_test[\"distance_from_city_center\"] = distance_from_city_center_t\n",
    "\n",
    "#FEATURES INCLUDED:\n",
    "features = [\"ceiling\", \"area_per_room\" ,  \"area_per_room_log\", \"rooms\", \"area_total\", \"area_kitchen\", \"area_living\", \"area_total_log\", \"area_kitchen_log\", \"area_living_log\",\n",
    "            \"floor\", \"new\", \"elevatern\", \"bathrooms_total\", \"bathrooms_shared\", \"bathrooms_private\", 'parking', 'heating',\n",
    "            \"latitude\", \"longitude\",\"district\", \"constructed\", \"condition\", \"seller\", \"total_balconies\", \"material\", \"stories\",'distance','back_azi','fwd_azi',\"floor/stories\",\n",
    "           \"distance_from_financial_center\", \"distance_from_city_center\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#MODEL:\n",
    "train_x = data[features]\n",
    "train_y = np.log1p(data['price']/data[\"area_total\"])\n",
    "test_x = data_test[features]\n",
    "\n",
    "param = {\n",
    "        'base_score' : 0.5,\n",
    "        'booster' : 'gbtree',\n",
    "        'colsample_bylevel' : 1,\n",
    "        'gamma' : 0,\n",
    "        'max_delta_step' : 0,\n",
    "        'n_jobs' : -1,\n",
    "        'nthread' : None,\n",
    "        'objective' : 'reg:squarederror',\n",
    "        'scale_pos_weight' : 1,\n",
    "        'seed' : None,\n",
    "        'lambda': 0.0024064014952485785, \n",
    "         'alpha': 0.001541503784279617, \n",
    "        'colsample_bytree': 0.43152225018148443, \n",
    "       'subsample': 0.8078473020517652, \n",
    "       'learning_rate': 0.013367834721822036, \n",
    "       'n_estimators': 5235, \n",
    "     'random_state': 291, \n",
    "      'max_depth': 9, \n",
    "    'min_child_weight': 13\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "model_xgb3 = XGBRegressor(**param)\n",
    "\n",
    "model_xgb3.fit(train_x,train_y)\n",
    "\n",
    "xgb3_preds = model_xgb3.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lgbm3 pipeline 0.15912 on test\n",
    "#MODEL\n",
    "train_x = data[features]\n",
    "train_y = np.log1p(data['price']/data[\"area_total\"])\n",
    "test_x = data_test[features]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_params = {'objective' : 'regression',\n",
    "    \"metric\": \"root_mean_squared_error\",\n",
    "    'random_state': 2020,\n",
    "    \"n_estimators\": 3000,\n",
    "    'boosting_type': 'gbdt', #better than dart\n",
    "    \"n_jobs\": -1,\n",
    " 'learning_rate': 0.009902216010560466, \n",
    " 'num_iterations': 9853, \n",
    " 'n_estimators': 2200, \n",
    " 'max_bin': 1145, \n",
    " 'num_leaves': 992, \n",
    " 'min_data_in_leaf': 21, \n",
    " 'min_sum_hessian_in_leaf': 6, \n",
    " 'bagging_fraction': 0.7553160099162841, \n",
    " 'bagging_freq': 1, \n",
    " 'max_depth': 5, \n",
    " 'lambda_l1': 0.001047756084491848, \n",
    " 'lambda_l2': 0.5231817241800534, \n",
    " 'min_gain_to_split': 0.01715842845568677\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_lgbm3 = LGBMRegressor(**best_params)  \n",
    "\n",
    "model_lgbm3.fit(train_x,train_y,verbose=False)\n",
    "\n",
    "lgbm3_preds = model_lgbm3.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#catb3 pipeline 0.15484\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "#MODEL:\n",
    "train_x = data[features]\n",
    "train_y = np.log1p(data['price']/data[\"area_total\"])\n",
    "test_x = data_test[features]\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "param = {\n",
    "\"objective\": \"RMSE\",\n",
    "'depth': 8, \n",
    " 'reg_lambda': 0.6424630162452156, \n",
    " 'learning_rate': 0.008856338969505724, \n",
    " 'n_estimators': 5356, \n",
    " 'max_bin': 1042, \n",
    " 'random_state': 1695, \n",
    " 'subsample': 0.4474582804576312}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_catb3 = CatBoostRegressor(**param)  \n",
    "\n",
    "model_catb3.fit(train_x,train_y,early_stopping_rounds=100,verbose=False)\n",
    "\n",
    "catb3_preds = model_catb3.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacked Model Pipeline\n",
    "train_x = data[features]\n",
    "train_y = np.log1p(data['price']/data[\"area_total\"])\n",
    "test_x = data_test[features]\n",
    "\n",
    "\n",
    "\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "\n",
    "stacked_model = StackingCVRegressor(regressors=(model_xgb1, model_xgb2, model_cat2, model_lgbm3,model_xgb3,model_catb3),\n",
    "                                meta_regressor=model_xgb3, #our best individual model becomes the META\n",
    "                                use_features_in_secondary=True,\n",
    "                                   verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "stacked_model.fit(train_x,train_y)\n",
    "\n",
    "stacked_preds = stacked_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-14T18:23:14.165716Z",
     "iopub.status.busy": "2021-10-14T18:23:14.165482Z",
     "iopub.status.idle": "2021-10-14T18:23:14.170927Z",
     "shell.execute_reply": "2021-10-14T18:23:14.170429Z",
     "shell.execute_reply.started": "2021-10-14T18:23:14.165693Z"
    }
   },
   "outputs": [],
   "source": [
    "#Weighted Averaging/Blending Model Pipeline\n",
    "final_preds = np.average(\n",
    "    [np.expm1(xgb_preds),\n",
    "     np.expm1(xgb2_preds)*data_test[\"area_total\"],\n",
    "     np.expm1(stacked_preds)*data_test[\"area_total\"],\n",
    "     np.expm1(catboost2_preds),\n",
    "     np.expm1(lgbm3_preds)*data_test[\"area_total\"],\n",
    "     np.expm1(xgb3_preds)*data_test[\"area_total\"],\n",
    "     np.expm1(catb3_preds)*data_test[\"area_total\"]\n",
    "    ],\n",
    "    weights = 1 / np.array([0.19558,  0.18874, 0.19250,0.19819,0.18979,0.19083,0.19596]) ** 6,  #Should be 4 by standard and then increase to 6 to squeeze more juice\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-14T18:23:14.172237Z",
     "iopub.status.busy": "2021-10-14T18:23:14.171967Z",
     "iopub.status.idle": "2021-10-14T18:23:14.927095Z",
     "shell.execute_reply": "2021-10-14T18:23:14.926131Z",
     "shell.execute_reply.started": "2021-10-14T18:23:14.172216Z"
    }
   },
   "outputs": [],
   "source": [
    "#Submission\n",
    "\n",
    "# Construct submission dataframe\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = data_test.id\n",
    "submission['price_prediction'] = final_preds # *0.99839    \n",
    "print(f'Generated {len(submission)} predictions')\n",
    "\n",
    "# Export submission to csv with headers\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Look at submitted csv\n",
    "print('\\nLine count of submission')\n",
    "!wc -l submission.csv\n",
    "\n",
    "print('\\nFirst 5 rows of submission')\n",
    "!head -n 10 submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
