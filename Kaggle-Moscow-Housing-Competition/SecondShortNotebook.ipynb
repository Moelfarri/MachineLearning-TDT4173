{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a22a46-5fd3-4064-a703-98c1dca87807",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-15T10:58:06.858639Z",
     "iopub.status.busy": "2021-11-15T10:58:06.857298Z",
     "iopub.status.idle": "2021-11-15T10:58:09.345774Z",
     "shell.execute_reply": "2021-11-15T10:58:09.346477Z",
     "shell.execute_reply.started": "2021-11-11T12:02:40.509122Z"
    },
    "papermill": {
     "duration": 2.50258,
     "end_time": "2021-11-15T10:58:09.346790",
     "exception": false,
     "start_time": "2021-11-15T10:58:06.844210",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Group 14\n",
    "## Competition Name : Moscow Housing\n",
    "## Elias Elfarri    , ID: 473700\n",
    "## Nora Valen       , ID: 490606\n",
    "## Muhammad Sarmad  , ID: 190729\n",
    "\n",
    "Please note the estimated run time of this notebook is around 40 minutes\n",
    "\n",
    "Predictions can be found under: SecondShortNotebook_submission.csv\n",
    "\n",
    "PUBLIC LEADERBOARD SCORE: 0.15274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c45b7f-ca5e-4463-9dfb-1e1c522ab992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "np.random.seed(123)\n",
    "sns.set_style('darkgrid')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "!ln -s /kaggle/input/moscow-housing-tdt4173 ./data\n",
    "!ls ./data | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb2fa1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T10:58:09.372113Z",
     "iopub.status.busy": "2021-11-15T10:58:09.371012Z",
     "iopub.status.idle": "2021-11-15T10:58:09.373021Z",
     "shell.execute_reply": "2021-11-15T10:58:09.373592Z",
     "shell.execute_reply.started": "2021-11-11T12:17:34.995792Z"
    },
    "papermill": {
     "duration": 0.018013,
     "end_time": "2021-11-15T10:58:09.373766",
     "exception": false,
     "start_time": "2021-11-15T10:58:09.355753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_log_error(y_true, y_pred):\n",
    "    # Alternatively: sklearn.metrics.mean_squared_log_error(y_true, y_pred) ** 0.5\n",
    "    assert (y_true >= 0).all() \n",
    "    assert (y_pred >= 0).all()\n",
    "    log_error = np.log1p(y_pred) - np.log1p(y_true)  # Note: log1p(x) = log(1 + x)\n",
    "    return np.mean(log_error ** 2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e55b2734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T10:58:09.400294Z",
     "iopub.status.busy": "2021-11-15T10:58:09.399405Z",
     "iopub.status.idle": "2021-11-15T10:58:09.632213Z",
     "shell.execute_reply": "2021-11-15T10:58:09.631403Z",
     "shell.execute_reply.started": "2021-11-11T12:02:43.002847Z"
    },
    "papermill": {
     "duration": 0.249474,
     "end_time": "2021-11-15T10:58:09.632404",
     "exception": false,
     "start_time": "2021-11-15T10:58:09.382930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "apartments = pd.read_csv('data/apartments_train.csv')\n",
    "buildings = pd.read_csv('data/buildings_train.csv')\n",
    "data = pd.merge(apartments, buildings.set_index('id'), how='left', left_on='building_id', right_index=True)\n",
    "\n",
    "apartments_test = pd.read_csv('data/apartments_test.csv')\n",
    "buildings_test = pd.read_csv('data/buildings_test.csv')\n",
    "data_test = pd.merge(apartments_test, buildings_test.set_index('id'), how='left', left_on='building_id', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c56956f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T10:58:09.666360Z",
     "iopub.status.busy": "2021-11-15T10:58:09.660826Z",
     "iopub.status.idle": "2021-11-15T10:58:16.845009Z",
     "shell.execute_reply": "2021-11-15T10:58:16.844353Z",
     "shell.execute_reply.started": "2021-11-11T12:02:43.258356Z"
    },
    "papermill": {
     "duration": 7.204308,
     "end_time": "2021-11-15T10:58:16.845160",
     "exception": false,
     "start_time": "2021-11-15T10:58:09.640852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:112: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:128: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:129: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:138: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:139: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:166: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:175: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:176: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "import pyproj\n",
    "from numpy.random import choice\n",
    "\n",
    "\n",
    "#FEATURE CLEANING\n",
    "data_test.latitude.iloc[90] = 55.568139\n",
    "data_test.longitude.iloc[90]= 37.481831\n",
    "data_test.latitude.iloc[23] = 55.568139\n",
    "data_test.longitude.iloc[23]= 37.481831\n",
    "data_test.latitude.iloc[2511] = 55.544066\n",
    "data_test.longitude.iloc[2511]= 37.482317\n",
    "data_test.latitude.iloc[6959] = 55.544066\n",
    "data_test.longitude.iloc[6959]= 37.482317\n",
    "data_test.latitude.iloc[5090] = 55.544066\n",
    "data_test.longitude.iloc[5090]= 37.482317\n",
    "data_test.latitude.iloc[8596] = 55.544066\n",
    "data_test.longitude.iloc[8596]= 37.482317\n",
    "data_test.latitude.iloc[2529] = 55.764335\n",
    "data_test.longitude.iloc[2529]= 37.907556\n",
    "data_test.latitude.iloc[4719] = 55.765430\n",
    "data_test.longitude.iloc[4719]= 37.928284\n",
    "data_test.latitude.iloc[9547] = 55.765430\n",
    "data_test.longitude.iloc[9547]= 37.928284\n",
    "\n",
    "data_test.district[data_test.building_id == 3803] = 11\n",
    "data_test.district[data_test.building_id == 4636] = 11\n",
    "data_test.district[data_test.building_id == 4412] = 11\n",
    "data_test.district[data_test.building_id == 926] = 3\n",
    "data_test.district[data_test.building_id == 4202] = 3\n",
    "data_test.district[data_test.building_id == 8811] = 3\n",
    "data_test.district[data_test.building_id == 6879] = 3\n",
    "data_test.district[data_test.building_id == 5667] = 3\n",
    "data_test.district[data_test.building_id == 2265] = 5\n",
    "data_test.district[data_test.building_id == 6403] = 5\n",
    "data_test.district[data_test.building_id == 7317] = 5\n",
    "data_test.district[data_test.building_id == 1647] = 5\n",
    "data_test.district[data_test.building_id == 183] = 5\n",
    "\n",
    "data.district[data.building_id == 2029] = 0\n",
    "data.district[data.building_id == 1255] = 0\n",
    "data.district[data.building_id == 4162] = 5\n",
    "\n",
    "\n",
    "#cleaning/engineering all elevators as one feature\n",
    "data['elevatern'] = data.apply(lambda row: 0 if (row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 0.0 ) # \n",
    "                               else( 1 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(2 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(3 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(4 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(5 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(6 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0)\n",
    "                                else(np.nan)\n",
    "                                )    \n",
    "                                )\n",
    "                                )\n",
    "                                )   \n",
    "                                )\n",
    "                                )\n",
    "                                ,axis=1)\n",
    "data_test['elevatern'] = data_test.apply(lambda row: 0 if (row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 0.0 ) # \n",
    "                               else( 1 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(2 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(3 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 0.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(4 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 0.0) # \n",
    "                                else(5 if(row[\"elevator_without\"] == 0 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0) # \n",
    "                                else(6 if(row[\"elevator_without\"] == 1 and row[\"elevator_passenger\"] == 1.0 and row[\"elevator_service\"] == 1.0)\n",
    "                                else(np.nan)\n",
    "                                ) \n",
    "                                )\n",
    "                                )\n",
    "                                )   \n",
    "                                )\n",
    "                                )\n",
    "                                ,axis=1)  \n",
    "mod = data['elevatern'].mode()\n",
    "data['elevatern'] = data['elevatern'].fillna(mod[0])\n",
    "data_test['elevatern'] = data_test['elevatern'].fillna(mod[0])\n",
    "\n",
    "\n",
    "data[\"bathrooms_shared\"] = data[\"bathrooms_shared\"].fillna(1)\n",
    "data[\"bathrooms_private\"] = data[\"bathrooms_private\"].fillna(1)\n",
    "data_test[\"bathrooms_shared\"] = data_test[\"bathrooms_shared\"].fillna(1)\n",
    "data_test[\"bathrooms_private\"] = data_test[\"bathrooms_private\"].fillna(1)\n",
    "\n",
    "\n",
    "\n",
    "data[\"parking\"] =  data[\"parking\"].fillna(3.0)\n",
    "data_test[\"parking\"] =  data_test[\"parking\"].fillna(3.0)\n",
    "data[\"heating\"] =  data[\"heating\"].fillna(0.0)\n",
    "data_test[\"heating\"] =  data_test[\"heating\"].fillna(0.0)\n",
    "\n",
    "#engineering and cleaning a feature\n",
    "data[\"total_balconies\"] = data[\"balconies\"] + data[\"loggias\"]\n",
    "data_test[\"total_balconies\"] = data_test[\"balconies\"] + data_test[\"loggias\"]\n",
    "data[\"total_balconies\"] =  data[\"total_balconies\"].fillna(1.0)\n",
    "data_test[\"total_balconies\"] =  data_test[\"total_balconies\"].fillna(1.0)\n",
    "\n",
    "\n",
    "#seller\n",
    "list_of_candidates = [0,1,2,3]\n",
    "probability_distribution  = [0.11, 0.33, 0.13, 0.43]\n",
    "number_of_items_to_pick = data['seller'].isna().sum()\n",
    "number_of_items_to_pick_test = data_test['seller'].isna().sum()\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "draw = choice(list_of_candidates, number_of_items_to_pick,\n",
    "              p=probability_distribution)\n",
    "draw_test = choice(list_of_candidates, number_of_items_to_pick_test,\n",
    "              p=probability_distribution)\n",
    "\n",
    "data['seller'][data.seller.isna()] = draw\n",
    "data_test['seller'][data_test.seller.isna()] = draw_test\n",
    "\n",
    "\n",
    "#area_kitchen and living\n",
    "percentage_area_data = pd.DataFrame()\n",
    "percentage_area_data[\"area_kitchen\"] = data[\"area_kitchen\"][data.area_living + data.area_kitchen < data.area_total]/data[\"area_total\"][data.area_living + data.area_kitchen < data.area_total]\n",
    "percentage_area_data[\"area_living\"] = data[\"area_living\"][data.area_living + data.area_kitchen < data.area_total]/data[\"area_total\"][data.area_living + data.area_kitchen < data.area_total]\n",
    "\n",
    "mean_kitchen = percentage_area_data[\"area_kitchen\"].mean()\n",
    "mean_living = percentage_area_data[\"area_living\"].mean()\n",
    "\n",
    "#to omit bugs\n",
    "data[\"area_kitchen_edit\"] = data[\"area_kitchen\"].copy()\n",
    "data[\"area_living_edit\"] = data[\"area_living\"].copy()\n",
    "\n",
    "data[\"area_kitchen_edit\"][(data.area_living + data.area_kitchen >= data.area_total) | (data.area_living.isna() | data.area_kitchen.isna())] = data.area_total*mean_kitchen\n",
    "data[\"area_living_edit\"][(data.area_living + data.area_kitchen >= data.area_total) | (data.area_living.isna() | data.area_kitchen.isna())] = data.area_total*mean_living\n",
    "\n",
    "data[\"area_kitchen\"] = data[\"area_kitchen_edit\"].copy()\n",
    "data[\"area_living\"] = data[\"area_living_edit\"].copy()\n",
    "\n",
    "#test_set\n",
    "data_test[\"area_kitchen_edit\"] = data_test[\"area_kitchen\"].copy()\n",
    "data_test[\"area_living_edit\"] = data_test[\"area_living\"].copy()\n",
    "\n",
    "data_test[\"area_kitchen_edit\"][(data_test.area_living + data_test.area_kitchen >= data_test.area_total) | (data_test.area_living.isna() | data_test.area_kitchen.isna())] = data_test.area_total*mean_kitchen\n",
    "data_test[\"area_living_edit\"][(data_test.area_living + data_test.area_kitchen >= data_test.area_total) | (data_test.area_living.isna() | data_test.area_kitchen.isna())] = data_test.area_total*mean_living\n",
    "\n",
    "\n",
    "data_test[\"area_kitchen\"] = data_test[\"area_kitchen_edit\"].copy()\n",
    "data_test[\"area_living\"] = data_test[\"area_living_edit\"].copy()\n",
    "        \n",
    "\n",
    "#ceiling    \n",
    "maxc = 9\n",
    "minc = 1\n",
    "data['ceiling'] = data.apply(lambda row: data[\"ceiling\"].mode()[0] if (row[\"ceiling\"] < minc or row[\"ceiling\"] > maxc ) else( row[\"ceiling\"]) ,axis=1) \n",
    "data_test['ceiling'] = data_test.apply(lambda row: data[\"ceiling\"].mode()[0] if (row[\"ceiling\"] < minc or row[\"ceiling\"] > maxc ) else( row[\"ceiling\"]) ,axis=1)  \n",
    "\n",
    "data['ceiling'][data.ceiling.isna() ] = data[\"ceiling\"].mode()[0]\n",
    "data_test['ceiling'][data_test.ceiling.isna() ] = data[\"ceiling\"].mode()[0]\n",
    "\n",
    "\n",
    "#condition\n",
    "var =  4.0\n",
    "data['condition'] = data['condition'].fillna(var)\n",
    "data_test['condition'] = data_test['condition'].fillna(var)\n",
    "\n",
    "\n",
    "#stories\n",
    "idss = data[[\"building_id\"]][data.floor > data.stories].sort_values(\"building_id\").drop_duplicates()\n",
    "for i in range(idss.size):\n",
    "    max_floor = data['floor'][data[\"building_id\"] == idss[\"building_id\"].iloc[i]].max()\n",
    "    data['stories'][data[\"building_id\"] == idss[\"building_id\"].iloc[i]] =  max_floor\n",
    "\n",
    "idss_test = data_test[[\"building_id\"]][data_test.floor > data_test.stories].sort_values(\"building_id\").drop_duplicates()\n",
    "for i in range(idss_test.size):\n",
    "    max_floor_test = data_test['floor'][data_test[\"building_id\"] == idss_test[\"building_id\"].iloc[i]].max()\n",
    "    data_test['stories'][data_test[\"building_id\"] == idss_test[\"building_id\"].iloc[i]] =  max_floor_test\n",
    "\n",
    "\n",
    "#material\n",
    "data.material[data.material==5] = 2.0 #merging monlith brick with monolith\n",
    "data.material[data.material==6] = 5.0 #stalin to 5\n",
    "\n",
    "data_test.material[data_test.material==5] = 2.0\n",
    "data_test.material[data_test.material==6] = 5.0\n",
    "\n",
    "data['material'][data.material.isna() ] = data['material'].mode()[0]\n",
    "data_test['material'][data_test.material.isna() ] = data['material'].mode()[0]\n",
    "\n",
    "#constructed, new:\n",
    "data['constructed'] = data.apply(\n",
    "    lambda row: 2019 if (np.isnan(row['constructed']) and ~np.isnan(row['new']) and row['new'] == 0.0) else( 2021 if (np.isnan(row['constructed'])) else row['constructed']),\n",
    "    axis=1\n",
    ")  \n",
    "data['new'] = data.apply(\n",
    "    lambda row: 0.0 if (np.isnan(row['new']) and row['constructed'] < 2020) else( 1.0 if (np.isnan(row['new'])) else row['new']),\n",
    "    axis=1\n",
    ")      \n",
    "\n",
    "\n",
    "data_test['constructed'] = data_test.apply(\n",
    "    lambda row: 2019 if (np.isnan(row['constructed']) and ~np.isnan(row['new']) and row['new'] == 0.0) else( 2021 if (np.isnan(row['constructed'])) else row['constructed']),\n",
    "    axis=1\n",
    ")  \n",
    "data_test['new'] = data_test.apply(\n",
    "    lambda row: 0.0 if (np.isnan(row['new']) and row['constructed'] < 2020) else( 1.0 if (np.isnan(row['new'])) else row['new']),\n",
    "    axis=1\n",
    ")  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FEATURE ENGINEERING:\n",
    "\n",
    "lon1 =  37.621390\n",
    "lat1 = 55.753098\n",
    "geodesic = pyproj.Geod(ellps='WGS84')\n",
    "distance_arr = []\n",
    "back_azimuth_arr = []\n",
    "fwd_azimuth_arr = []\n",
    "for i in range(len(data[\"longitude\"])):\n",
    "    fwd_azimuth,back_azimuth,distance = geodesic.inv(lon1, lat1, data[\"longitude\"][i], data[\"latitude\"][i])\n",
    "    distance_arr.append(distance)\n",
    "    back_azimuth_arr.append(back_azimuth)\n",
    "    fwd_azimuth_arr.append(fwd_azimuth)\n",
    "\n",
    "data['fwd_azi'] = fwd_azimuth_arr\n",
    "data['distance'] = distance_arr\n",
    "data['back_azi'] = back_azimuth_arr\n",
    "\n",
    "\n",
    "geodesic = pyproj.Geod(ellps='WGS84')\n",
    "distance_arr = []\n",
    "back_azimuth_arr = []\n",
    "fwd_azimuth_arr = []\n",
    "for i in range(len(data_test[\"longitude\"])):\n",
    "    fwd_azimuth,back_azimuth,distance = geodesic.inv(lon1, lat1, data_test[\"longitude\"][i], data_test[\"latitude\"][i])\n",
    "    distance_arr.append(distance)\n",
    "    back_azimuth_arr.append(back_azimuth)\n",
    "    fwd_azimuth_arr.append(fwd_azimuth)\n",
    "\n",
    "data_test['fwd_azi'] = fwd_azimuth_arr\n",
    "data_test['distance'] = distance_arr\n",
    "data_test['back_azi'] = back_azimuth_arr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data['area_per_room'] = data['area_total']/data['rooms']\n",
    "data_test['area_per_room'] = data_test['area_total']/data_test['rooms']\n",
    "\n",
    "data['area_per_room_log'] = np.log1p(data['area_per_room'])\n",
    "data_test['area_per_room_log'] = np.log1p(data_test['area_per_room'])\n",
    "\n",
    "data['area_total_log'] = np.log1p(data['area_total'])\n",
    "data['area_kitchen_log'] = np.log1p(data['area_kitchen'])\n",
    "data['area_living_log'] = np.log1p(data['area_living'])\n",
    "\n",
    "data_test['area_total_log'] = np.log1p(data_test['area_total'])\n",
    "data_test['area_kitchen_log'] = np.log1p(data_test['area_kitchen'])\n",
    "data_test['area_living_log'] = np.log1p(data_test['area_living'])\n",
    "\n",
    "\n",
    "data[\"bathrooms_total\"] = data.bathrooms_shared + data.bathrooms_private\n",
    "data_test[\"bathrooms_total\"] = data_test.bathrooms_shared + data_test.bathrooms_private\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#floor/stories\n",
    "data[\"floor/stories\"] = data[\"floor\"]/data[\"stories\"]\n",
    "data_test[\"floor/stories\"] = data_test[\"floor\"]/data_test[\"stories\"]\n",
    "\n",
    "\n",
    "#euclidean financial distance from city center\n",
    "financial_coords = (37.535497858, 55.741330368)\n",
    "distance_from_city_center = np.sqrt((financial_coords[0] - data[\"longitude\"])**2+(financial_coords[1] - data[\"latitude\"])**2)\n",
    "data[\"distance_from_financial_center\"] = distance_from_city_center\n",
    "\n",
    "distance_from_city_center_t = np.sqrt((financial_coords[0] - data_test[\"longitude\"])**2+(financial_coords[1] - data_test[\"latitude\"])**2)\n",
    "data_test[\"distance_from_financial_center\"] = distance_from_city_center_t\n",
    "\n",
    "\n",
    "#euclidean distance from city center\n",
    "origin_coordinates = (37.621390,55.753098)\n",
    "distance_from_city_center = np.sqrt((origin_coordinates[0] - data[\"longitude\"])**2+(origin_coordinates[1] - data[\"latitude\"])**2)\n",
    "data[\"distance_from_city_center\"] = distance_from_city_center\n",
    "\n",
    "distance_from_city_center_t = np.sqrt((origin_coordinates[0] - data_test[\"longitude\"])**2+(origin_coordinates[1] - data_test[\"latitude\"])**2)\n",
    "data_test[\"distance_from_city_center\"] = distance_from_city_center_t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FEATURES INCLUDED:\n",
    "features = [\"ceiling\", \"area_per_room\" ,  \"area_per_room_log\", \"rooms\", \"area_total\", \"area_kitchen\", \"area_living\", \"area_total_log\", \"area_kitchen_log\", \"area_living_log\",\n",
    "            \"floor\", \"new\", \"elevatern\", \"bathrooms_total\", \"bathrooms_shared\", \"bathrooms_private\", 'parking', 'heating',\n",
    "            \"latitude\", \"longitude\",\"district\", \"constructed\", \"condition\", \"seller\", \"total_balconies\", \"material\", \"stories\",'distance','back_azi','fwd_azi',\"floor/stories\",\n",
    "           \"distance_from_financial_center\", \"distance_from_city_center\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fea0c4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T10:58:16.871991Z",
     "iopub.status.busy": "2021-11-15T10:58:16.871219Z",
     "iopub.status.idle": "2021-11-15T10:58:17.071747Z",
     "shell.execute_reply": "2021-11-15T10:58:17.071166Z",
     "shell.execute_reply.started": "2021-11-11T12:46:19.402461Z"
    },
    "papermill": {
     "duration": 0.21677,
     "end_time": "2021-11-15T10:58:17.071917",
     "exception": false,
     "start_time": "2021-11-15T10:58:16.855147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#GroupKfold cross validation based on building split\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score, cross_val_predict\n",
    "\n",
    "kfolds = 10\n",
    "gkf = GroupKFold( n_splits=kfolds)\n",
    "groups = data.building_id\n",
    "\n",
    "def group_cv(model, y, data=data[features], cv=gkf, groups=groups):\n",
    "    model_preds = cross_val_predict(model, X=data, y=y, cv=gkf , groups =groups)\n",
    "    return model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "042d355b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T10:58:17.101851Z",
     "iopub.status.busy": "2021-11-15T10:58:17.100798Z",
     "iopub.status.idle": "2021-11-15T10:58:18.298108Z",
     "shell.execute_reply": "2021-11-15T10:58:18.298687Z",
     "shell.execute_reply.started": "2021-11-11T13:04:48.763272Z"
    },
    "papermill": {
     "duration": 1.217014,
     "end_time": "2021-11-15T10:58:18.299029",
     "exception": false,
     "start_time": "2021-11-15T10:58:17.082015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CROSS VALIDATION IS DONE HERE:\n",
    "#LGBM\n",
    "from lightgbm import LGBMRegressor\n",
    "best_params = {'objective' : 'regression',\n",
    "    \"metric\": \"root_mean_squared_error\",\n",
    "    'random_state': 2020,\n",
    "    \"n_estimators\": 3000,\n",
    "    'boosting_type': 'gbdt', #better than dart\n",
    "    \"n_jobs\": -1,\n",
    " 'learning_rate': 0.009902216010560466, \n",
    " 'num_iterations': 9853, \n",
    " 'n_estimators': 2200, \n",
    " 'max_bin': 1145, \n",
    " 'num_leaves': 992, \n",
    " 'min_data_in_leaf': 21, \n",
    " 'min_sum_hessian_in_leaf': 6, \n",
    " 'bagging_fraction': 0.7553160099162841, \n",
    " 'bagging_freq': 1, \n",
    " 'max_depth': 5, \n",
    " 'lambda_l1': 0.001047756084491848, \n",
    " 'lambda_l2': 0.5231817241800534, \n",
    " 'min_gain_to_split': 0.01715842845568677\n",
    "    }\n",
    "model_lgbm3 = LGBMRegressor(**best_params)\n",
    "\n",
    "\n",
    "\n",
    "#Catboost\n",
    "from catboost import CatBoostRegressor\n",
    "param = {\n",
    "\"objective\": \"RMSE\",\n",
    "'depth': 8, \n",
    " 'reg_lambda': 0.6424630162452156, \n",
    " 'learning_rate': 0.008856338969505724, \n",
    " 'n_estimators': 5356, \n",
    " 'max_bin': 1042, \n",
    " 'random_state': 1695, \n",
    " 'subsample': 0.4474582804576312,\n",
    "    \"verbose\": False}\n",
    "model_catb3 = CatBoostRegressor(**param)  \n",
    "\n",
    "\n",
    "\n",
    "#Xgboost\n",
    "from xgboost import XGBRegressor\n",
    "param = {\n",
    "        'base_score' : 0.5,\n",
    "        'booster' : 'gbtree',\n",
    "        'colsample_bylevel' : 1,\n",
    "        'gamma' : 0,\n",
    "        'max_delta_step' : 0,\n",
    "        'n_jobs' : -1,\n",
    "        'nthread' : None,\n",
    "        'objective' : 'reg:squarederror',\n",
    "        'scale_pos_weight' : 1,\n",
    "        'seed' : None,\n",
    "        'lambda': 0.0024064014952485785, \n",
    "         'alpha': 0.001541503784279617, \n",
    "        'colsample_bytree': 0.43152225018148443, \n",
    "       'subsample': 0.8078473020517652, \n",
    "       'learning_rate': 0.013367834721822036, \n",
    "       'n_estimators': 5235, \n",
    "     'random_state': 291, \n",
    "      'max_depth': 9, \n",
    "    'min_child_weight': 13\n",
    "}\n",
    "model_xgb3 = XGBRegressor(**param)\n",
    "\n",
    "\n",
    "\n",
    "#From GroupKFolding on 10 ksplits on building_id\n",
    "#LGBM3 SCORE: 0.18979521325245455\n",
    "#XGBOOST3 SCORE: 0.1908350746986002\n",
    "#CATBOOST3 SCORE: 0.19596734972841498\n",
    "\n",
    "#comment these out when submitting:\n",
    "#print(\"LOGGING GROUP KFOLDING 10 SPLITS\")\n",
    "\n",
    "#lgbm3_cv_preds = group_cv(model_lgbm3, np.log1p(data.price/data.area_total))\n",
    "#print(\"LGBM3 SCORE:\", root_mean_squared_log_error(data.price, np.expm1(lgbm3_cv_preds)*data.area_total))\n",
    "\n",
    "#xgb3_cv_preds = group_cv(model_xgb3, np.log1p(data.price/data.area_total))\n",
    "#print(\"XGBOOST3 SCORE:\", root_mean_squared_log_error(data.price, np.expm1(xgb3_cv_preds)*data.area_total))\n",
    "\n",
    "#cat3_cv_preds = group_cv(model_catb3, np.log1p(data.price/data.area_total))\n",
    "#print(\"CATBOOST3 SCORE:\", root_mean_squared_log_error(data.price, np.expm1(cat3_cv_preds)*data.area_total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9c0ef55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T10:58:18.339680Z",
     "iopub.status.busy": "2021-11-15T10:58:18.338964Z",
     "iopub.status.idle": "2021-11-15T11:37:04.145511Z",
     "shell.execute_reply": "2021-11-15T11:37:04.146279Z"
    },
    "papermill": {
     "duration": 2325.836726,
     "end_time": "2021-11-15T11:37:04.146583",
     "exception": false,
     "start_time": "2021-11-15T10:58:18.309857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001047756084491848, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001047756084491848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7553160099162841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7553160099162841\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.01715842845568677, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.01715842845568677\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5231817241800534, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5231817241800534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001047756084491848, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001047756084491848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7553160099162841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7553160099162841\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.01715842845568677, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.01715842845568677\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5231817241800534, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5231817241800534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001047756084491848, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001047756084491848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7553160099162841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7553160099162841\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.01715842845568677, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.01715842845568677\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5231817241800534, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5231817241800534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001047756084491848, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001047756084491848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7553160099162841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7553160099162841\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.01715842845568677, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.01715842845568677\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5231817241800534, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5231817241800534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001047756084491848, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001047756084491848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7553160099162841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7553160099162841\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.01715842845568677, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.01715842845568677\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5231817241800534, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5231817241800534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.001047756084491848, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001047756084491848\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7553160099162841, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7553160099162841\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=21, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=21\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=6, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] min_gain_to_split is set=0.01715842845568677, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.01715842845568677\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5231817241800534, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5231817241800534\n",
      "Generated 9937 predictions\n",
      "\n",
      "Line count of submission\n",
      "9938 submission.csv\n",
      "\n",
      "First 5 rows of submission\n",
      "id,price_prediction\n",
      "23285,30489830.437500004\n",
      "23286,9074835.84375\n",
      "23287,6114542.6375\n",
      "23288,8301964.125\n",
      "23289,5360123.90625\n",
      "23290,7079245.625\n",
      "23291,7252458.2265625\n",
      "23292,9786362.8125\n",
      "23293,5849088.25\n"
     ]
    }
   ],
   "source": [
    "#STACKED MODEL\n",
    "train_x = data[features]\n",
    "train_y = np.log1p(data['price']/data[\"area_total\"])\n",
    "test_x = data_test[features]\n",
    "\n",
    "\n",
    "\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "stacked_model = StackingCVRegressor(regressors=(model_lgbm3, model_catb3, model_xgb3),\n",
    "                                meta_regressor=model_xgb3, #our best individual model becomes the META\n",
    "                                use_features_in_secondary=True,\n",
    "                                   verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "stacked_model.fit(train_x,train_y)\n",
    "stacked_preds = stacked_model.predict(test_x)\n",
    "\n",
    "final_preds = np.expm1(stacked_preds)*data_test[\"area_total\"]\n",
    "\n",
    "\n",
    "#submission\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = data_test.id\n",
    "submission['price_prediction'] = final_preds     \n",
    "print(f'Generated {len(submission)} predictions')\n",
    "\n",
    "# Export submission to csv with headers\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Look at submitted csv\n",
    "print('\\nLine count of submission')\n",
    "!wc -l submission.csv\n",
    "\n",
    "print('\\nFirst 5 rows of submission')\n",
    "!head -n 10 submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2348.370896,
   "end_time": "2021-11-15T11:37:05.180635",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-11-15T10:57:56.809739",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
